# ðŸ§  Multi-Agent Research Assistant (Offline LangChain + Ollama)

This project showcases a **fully offline, multi-agent system** using [LangChain](https://www.langchain.com/) and [Ollama](https://ollama.com/) with the **Mistral** language model.

## ðŸ”§ What It Does
- **Researcher Agent:** Plans what needs to be searched or analyzed
- **Summarizer Agent:** Summarizes mock (or real) content
- **Evaluator Agent:** Checks summary quality and recommends improvements

## ðŸ–¥ How to Run
### 1. Install Ollama and Pull a Model
```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama pull mistral
```

### 2. Install Python Dependencies
```bash
pip install -r requirements.txt
```

### 3. Run the Project
```bash
python main.py
```

## ðŸ“‚ Project Structure
```
multi_agent_research_assistant/
â”œâ”€â”€ main.py
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ researcher_agent.py
â”‚   â”œâ”€â”€ summarizer_agent.py
â”‚   â””â”€â”€ evaluator_agent.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ðŸ“Œ Ideal For
- Resume portfolio
- AI pipeline showcase
- LangChain & Ollama offline demos

---

Built with ðŸ’¡ by **Likhil Penujuli**
